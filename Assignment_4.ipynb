{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuUYViYpAyXgkANRUnR1Sz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngochif/fngochi_64061/blob/main/Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the IMDB Dataset**"
      ],
      "metadata": {
        "id": "EEK01tiEQbKD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsSh18qBELfK",
        "outputId": "09271257-5f06-49b6-8200-81f180a8c961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  15.6M      0  0:00:05  0:00:05 --:--:-- 17.2M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN_qYLzRET8E",
        "outputId": "349d193a-cfad-4eeb-bc31-5816aa2669e7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'aclImdb/train/unsup': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat aclImdb/train/pos/4077_10.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZvxJyCQEfSN",
        "outputId": "abfee79d-b9a6-42a8-8185-6b698b3765f1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preparation**"
      ],
      "metadata": {
        "id": "q-TYBJWba18-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pathlib, shutil, random\n",
        "\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "for category in (\"neg\", \"pos\"):\n",
        "\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)\n",
        "    num_val_samples = int(0.5 * len(files))\n",
        "    val_files = files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    val_dir / category / fname)"
      ],
      "metadata": {
        "id": "XsUh-RbkEkUT"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\", batch_size=batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6UmOrwmEnsF",
        "outputId": "2d807938-fd01-429e-8f6e-95107170b6e1"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 files belonging to 2 classes.\n",
            "Found 15000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the parameters for the new requirements**"
      ],
      "metadata": {
        "id": "CUZ_YWiXW5sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 10000  # Consider only the top 10,000 words\n",
        "sequence_length = 150  # Cutoff reviews after 150 words\n",
        "training_samples = 100  # Number of training samples\n",
        "validation_samples = 10000  # Number of validation samples\n",
        "batch_size = 25  # Batch size for training"
      ],
      "metadata": {
        "id": "PzKe5RipGXZD"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing the integer sequence datasets according to new requirements**\n",
        "\n"
      ],
      "metadata": {
        "id": "xVv_3NOEbQ_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization, Embedding, GlobalAveragePooling1D, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Load datasets\n",
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\",\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\",\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gaayWoAGhAo",
        "outputId": "9b600621-13f5-4278-c4cc-246e43b0251b"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 files belonging to 2 classes.\n",
            "Found 15000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limit the dataset to an exact number of samples\n",
        "def limit_dataset(ds, num_samples):\n",
        "    return ds.unbatch().take(num_samples).batch(batch_size)\n",
        "\n",
        "# Apply the limiting function\n",
        "train_ds = limit_dataset(raw_train_ds, training_samples)\n",
        "val_ds = limit_dataset(raw_val_ds, validation_samples)\n",
        "test_ds = raw_test_ds\n",
        "# Text Vectorization\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=max_features,\n",
        "    output_sequence_length=sequence_length\n",
        ")\n",
        "train_text = train_ds.map(lambda x, y: x)\n",
        "text_vectorization.adapt(train_text)"
      ],
      "metadata": {
        "id": "sKCuxViBTyy6"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slice the datasets\n",
        "train_ds = raw_train_ds.take(training_samples // batch_size)\n",
        "val_ds = raw_val_ds.take(validation_samples // batch_size)\n",
        "test_ds = raw_test_ds\n",
        "\n",
        "# Text Vectorization\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=max_features,\n",
        "    output_sequence_length=sequence_length\n",
        ")\n",
        "train_text = train_ds.map(lambda x, y: x)\n",
        "text_vectorization.adapt(train_text)"
      ],
      "metadata": {
        "id": "iUJksN5HG0Ou"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_dataset_size(dataset):\n",
        "    size = 0\n",
        "    for batch in dataset:\n",
        "        size += tf.shape(batch[0])[0]  # count the number of items in the batch\n",
        "    return size\n",
        "\n",
        "# Calculate the sizes\n",
        "train_size = calculate_dataset_size(train_ds)\n",
        "val_size = calculate_dataset_size(val_ds)\n",
        "test_size = calculate_dataset_size(test_ds)\n",
        "\n",
        "# Print the sizes\n",
        "print(f\"Training Dataset Size: {train_size}\")\n",
        "print(f\"Validation Dataset Size: {val_size}\")\n",
        "print(f\"Test Dataset Size: {test_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koXiG4-PSefn",
        "outputId": "89b8d4ba-34cb-4939-b79b-8ebbdfeb00f3"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Size: 100\n",
            "Validation Dataset Size: 10000\n",
            "Test Dataset Size: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the datasets\n",
        "train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y))\n",
        "test_ds = raw_test_ds.map(lambda x, y: (text_vectorization(x), y))"
      ],
      "metadata": {
        "id": "i1EmQMCwHZwA"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training a Model that uses an Embedding layer trained from scratch**"
      ],
      "metadata": {
        "id": "v6uVh3nG_-o4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(input_dim=max_features, output_dim=256)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\n",
        "print(f\"Test acc: {model.evaluate(test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTdmafg5jf9p",
        "outputId": "3bf22787-0a78-4f80-d907-4db851135f73"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_10 (Embedding)    (None, None, 256)         2560000   \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirecti  (None, 64)                73984     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2634049 (10.05 MB)\n",
            "Trainable params: 2634049 (10.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 25s 6s/step - loss: 0.6943 - accuracy: 0.5300 - val_loss: 0.6928 - val_accuracy: 0.5030\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 42s 14s/step - loss: 0.6811 - accuracy: 0.6400 - val_loss: 0.6936 - val_accuracy: 0.5017\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 22s 7s/step - loss: 0.6790 - accuracy: 0.6200 - val_loss: 0.6938 - val_accuracy: 0.5025\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 22s 7s/step - loss: 0.6669 - accuracy: 0.7000 - val_loss: 0.6945 - val_accuracy: 0.5045\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 23s 8s/step - loss: 0.6567 - accuracy: 0.6000 - val_loss: 0.6951 - val_accuracy: 0.5070\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.6570 - accuracy: 0.6000 - val_loss: 0.6963 - val_accuracy: 0.5067\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 22s 7s/step - loss: 0.6265 - accuracy: 0.7100 - val_loss: 0.7010 - val_accuracy: 0.5077\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 22s 7s/step - loss: 0.6289 - accuracy: 0.6900 - val_loss: 0.7044 - val_accuracy: 0.5160\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.5983 - accuracy: 0.7200 - val_loss: 0.7114 - val_accuracy: 0.5162\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 42s 14s/step - loss: 0.6137 - accuracy: 0.7200 - val_loss: 0.7072 - val_accuracy: 0.5206\n",
            "1000/1000 [==============================] - 50s 47ms/step - loss: 0.6932 - accuracy: 0.4979\n",
            "Test acc: 0.498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training a Model Using GLOVE Pretrained Embedding**"
      ],
      "metadata": {
        "id": "2Y31U8wVIF6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "mxOtRycAIIVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parsing the GloVe word-embeddings file"
      ],
      "metadata": {
        "id": "-bgTpOZ-I3yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(f\"Found {len(embeddings_index)} word vectors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtWCpZslI9am",
        "outputId": "f622ff8b-8c25-48c6-b943-bfe59b0c481b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "embedding_matrix = np.zeros((max_features, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i < max_features:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "D78fTwbdMDTY"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = layers.Embedding(\n",
        "    max_features,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        "    mask_zero=True,\n",
        ")"
      ],
      "metadata": {
        "id": "418VQFvqNBOP"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Preparing the GloVe word-embeddings matrix"
      ],
      "metadata": {
        "id": "Ad3S7wEwBUF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n",
        "print(f\"Test acc: {model.evaluate(test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAX_1VEVBXml",
        "outputId": "3a277fcf-2ce3-4d3c-e567-e34f6144dc35"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_9 (Embedding)     (None, None, 100)         1000000   \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirecti  (None, 64)                34048     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1034113 (3.94 MB)\n",
            "Trainable params: 34113 (133.25 KB)\n",
            "Non-trainable params: 1000000 (3.81 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 52s 13s/step - loss: 0.7216 - accuracy: 0.4700 - val_loss: 0.6952 - val_accuracy: 0.5078\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 21s 7s/step - loss: 0.7040 - accuracy: 0.5000 - val_loss: 0.7143 - val_accuracy: 0.5013\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 22s 7s/step - loss: 0.6741 - accuracy: 0.5300 - val_loss: 0.6995 - val_accuracy: 0.5023\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 17s 5s/step - loss: 0.6817 - accuracy: 0.5900 - val_loss: 0.6954 - val_accuracy: 0.5046\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 32s 11s/step - loss: 0.6761 - accuracy: 0.5900 - val_loss: 0.6939 - val_accuracy: 0.5109\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 34s 11s/step - loss: 0.6970 - accuracy: 0.5300 - val_loss: 0.6936 - val_accuracy: 0.5101\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 22s 7s/step - loss: 0.6699 - accuracy: 0.6200 - val_loss: 0.6948 - val_accuracy: 0.5051\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 18s 6s/step - loss: 0.6834 - accuracy: 0.5900 - val_loss: 0.7056 - val_accuracy: 0.5028\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 22s 7s/step - loss: 0.6527 - accuracy: 0.6500 - val_loss: 0.7008 - val_accuracy: 0.5025\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 17s 6s/step - loss: 0.6502 - accuracy: 0.6600 - val_loss: 0.6947 - val_accuracy: 0.5088\n",
            "1000/1000 [==============================] - 50s 44ms/step - loss: 0.6938 - accuracy: 0.5089\n",
            "Test acc: 0.509\n"
          ]
        }
      ]
    }
  ]
}